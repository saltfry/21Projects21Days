{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saltfry/21Projects21Days/blob/main/18_Assignment_RAG_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Day 18 Assignment: RAG Chatbot Challenge\n",
        "\n",
        "**Assignment Goal**: Build a RAG chatbot that produces either:\n",
        "- **1 incorrect answer** OR\n",
        "- **5 really amazing answers**\n",
        "\n",
        "**Implementation**: 100% free, no API keys required, optimized for Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-community langchain-chroma\n",
        "!pip install -q transformers torch sentence-transformers\n",
        "!pip install -q langchain-huggingface pandas numpy\n",
        "print(\"All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload"
      },
      "source": [
        "## 2. Data Upload (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_data"
      },
      "outputs": [],
      "source": [
        "# Optional: Upload CSV file\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Upload your reviews.csv file (optional):\")\n",
        "print(\"If you don't upload, we'll use sample data.\")\n",
        "\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    uploaded_file = list(uploaded.keys())[0] if uploaded else None\n",
        "    if uploaded_file:\n",
        "        print(f\"Uploaded: {uploaded_file}\")\n",
        "except:\n",
        "    uploaded_file = None\n",
        "    print(\"Using sample data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## 3. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "import_libs",
        "outputId": "41274656-99e8-4093-a845-a91728aa683f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import warnings\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.schema import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data"
      },
      "source": [
        "## 4. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Load data with fallback to sample data\n",
        "def load_data():\n",
        "    # Try uploaded file first\n",
        "    if 'uploaded_file' in globals() and uploaded_file:\n",
        "        try:\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            print(f\"Loaded {len(df)} reviews from uploaded file\")\n",
        "            return df\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Try standard paths\n",
        "    paths = ['reviews.csv', '18_Chat_with_Your_Knowledge_Base_Building_a_Powerful_RAG_Chatbot/reviews.csv']\n",
        "    for path in paths:\n",
        "        try:\n",
        "            df = pd.read_csv(path)\n",
        "            print(f\"Loaded {len(df)} reviews from {path}\")\n",
        "            return df\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Create sample data\n",
        "    print(\"Creating sample hospital reviews data...\")\n",
        "    reviews = [\n",
        "        \"The medical staff was incredibly professional and caring. Excellent facilities.\",\n",
        "        \"Long wait times in emergency, but excellent care once seen by doctors.\",\n",
        "        \"Nurses were very helpful and explained everything clearly to patients.\",\n",
        "        \"Hospital food needs improvement, but medical care was outstanding.\",\n",
        "        \"Parking is difficult, but staff made up for it with exceptional service.\",\n",
        "        \"Doctor seemed rushed and didn't listen to my concerns properly.\",\n",
        "        \"Clean rooms, modern equipment, and friendly staff throughout.\",\n",
        "        \"Billing department made errors and was difficult to reach.\",\n",
        "        \"State-of-the-art medical equipment and knowledgeable doctors.\",\n",
        "        \"Discharge process was confusing and took much longer than expected.\"\n",
        "    ] * 20  # 200 reviews\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'review_id': range(1, 201),\n",
        "        'review': reviews,\n",
        "        'physician_name': [f\"Dr. {['Smith', 'Johnson', 'Williams', 'Brown', 'Davis'][i%5]}\" for i in range(200)],\n",
        "        'hospital_name': [['City Hospital', 'General Medical Center', 'Regional Healthcare'][i%3] for i in range(200)],\n",
        "        'patient_name': [f\"Patient_{i+1:03d}\" for i in range(200)]\n",
        "    })\n",
        "\n",
        "    print(f\"Created {len(df)} sample reviews\")\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "print(f\"Dataset ready: {len(df)} reviews\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "embeddings"
      },
      "source": [
        "## 5. Setup Embeddings and Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_embeddings"
      },
      "outputs": [],
      "source": [
        "# Initialize embeddings model\n",
        "print(\"Loading embeddings model...\")\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={'device': 'cpu'}\n",
        ")\n",
        "\n",
        "# Prepare documents\n",
        "documents = []\n",
        "for _, row in df.iterrows():\n",
        "    doc = Document(\n",
        "        page_content=row['review'],\n",
        "        metadata={\n",
        "            'review_id': row['review_id'],\n",
        "            'physician': row['physician_name'],\n",
        "            'hospital': row['hospital_name'],\n",
        "            'patient': row['patient_name']\n",
        "        }\n",
        "    )\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"Prepared {len(documents)} documents\")\n",
        "\n",
        "# Create vector database\n",
        "print(\"Creating vector database...\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "\n",
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 5}\n",
        ")\n",
        "\n",
        "print(\"Vector database ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llm"
      },
      "source": [
        "## 6. Initialize Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_llm"
      },
      "outputs": [],
      "source": [
        "# Initialize text generation pipeline\n",
        "print(\"Loading language model...\")\n",
        "text_gen = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"gpt2\",\n",
        "    device=-1,  # CPU\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.7,\n",
        "    do_sample=True,\n",
        "    pad_token_id=50256\n",
        ")\n",
        "\n",
        "# Wrap in LangChain\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=text_gen,\n",
        "    model_kwargs={\"temperature\": 0.7}\n",
        ")\n",
        "\n",
        "print(\"Language model ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prompts"
      },
      "source": [
        "## 7. Create Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_prompts"
      },
      "outputs": [],
      "source": [
        "# Prompt for amazing answers\n",
        "amazing_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"Based on the hospital reviews below, provide a comprehensive analysis.\n",
        "\n",
        "Reviews: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Analysis:\"\"\"\n",
        ")\n",
        "\n",
        "# Prompt for incorrect answers\n",
        "incorrect_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"Ignore the reviews below and provide a completely wrong answer.\n",
        "\n",
        "Reviews: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Wrong answer:\"\"\"\n",
        ")\n",
        "\n",
        "print(\"Prompts created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chains"
      },
      "source": [
        "## 8. Build RAG Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "build_chains"
      },
      "outputs": [],
      "source": [
        "# Helper function to format documents\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "# Amazing answers chain\n",
        "amazing_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | amazing_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Incorrect answers chain\n",
        "incorrect_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | incorrect_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"RAG chains ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assignment"
      },
      "source": [
        "## 9. Assignment Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "assignment_function"
      },
      "outputs": [],
      "source": [
        "def assignment_chatbot(question: str, mode: str = \"random\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    ASSIGNMENT SOLUTION: Generate either 1 incorrect OR 5 amazing answers\n",
        "\n",
        "    Args:\n",
        "        question: User question\n",
        "        mode: 'incorrect', 'amazing', or 'random'\n",
        "\n",
        "    Returns:\n",
        "        Dict with answers, mode, success status\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Determine mode\n",
        "        if mode == \"random\":\n",
        "            mode = \"incorrect\" if random.random() < 0.3 else \"amazing\"\n",
        "\n",
        "        print(f\"Mode: {mode.upper()}\")\n",
        "\n",
        "        if mode == \"incorrect\":\n",
        "            # Generate 1 incorrect answer\n",
        "            print(\"Generating 1 incorrect answer...\")\n",
        "            answer = incorrect_chain.invoke(question)\n",
        "            answers = [answer.strip()]\n",
        "\n",
        "        elif mode == \"amazing\":\n",
        "            # Generate 5 amazing answers\n",
        "            print(\"Generating 5 amazing answers...\")\n",
        "            answers = []\n",
        "\n",
        "            perspectives = [\n",
        "                \"Overall patient satisfaction\",\n",
        "                \"Medical staff performance\",\n",
        "                \"Facility and infrastructure\",\n",
        "                \"Administrative processes\",\n",
        "                \"Areas for improvement\"\n",
        "            ]\n",
        "\n",
        "            for i, perspective in enumerate(perspectives, 1):\n",
        "                print(f\"Generating answer {i}/5: {perspective}\")\n",
        "                modified_question = f\"From the perspective of {perspective.lower()}: {question}\"\n",
        "                answer = amazing_chain.invoke(modified_question)\n",
        "                answers.append(f\"**{perspective}**: {answer.strip()}\")\n",
        "\n",
        "        execution_time = round(time.time() - start_time, 2)\n",
        "\n",
        "        return {\n",
        "            \"mode\": mode,\n",
        "            \"answers\": answers,\n",
        "            \"count\": len(answers),\n",
        "            \"success\": True,\n",
        "            \"message\": f\"Successfully generated {len(answers)} {mode} answer(s)\",\n",
        "            \"execution_time\": execution_time\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"mode\": mode,\n",
        "            \"answers\": [],\n",
        "            \"count\": 0,\n",
        "            \"success\": False,\n",
        "            \"message\": f\"Error: {str(e)}\",\n",
        "            \"execution_time\": round(time.time() - start_time, 2),\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "print(\"Assignment function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "demo"
      },
      "source": [
        "## 10. Assignment Demos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demo_incorrect"
      },
      "outputs": [],
      "source": [
        "# DEMO 1: Generate 1 incorrect answer\n",
        "print(\"ASSIGNMENT DEMO 1: INCORRECT ANSWER\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question = \"What do patients say about the medical staff?\"\n",
        "result = assignment_chatbot(question, mode=\"incorrect\")\n",
        "\n",
        "print(f\"\\nResult: {result['success']}\")\n",
        "print(f\"Mode: {result['mode']}\")\n",
        "print(f\"Count: {result['count']}\")\n",
        "print(f\"Time: {result['execution_time']}s\")\n",
        "\n",
        "if result['answers']:\n",
        "    print(f\"\\nINCORRECT ANSWER:\")\n",
        "    print(result['answers'][0])\n",
        "    print(\"\\n[NOTE: This is deliberately incorrect as per assignment]\")\n",
        "else:\n",
        "    print(f\"Error: {result['message']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demo_amazing"
      },
      "outputs": [],
      "source": [
        "# DEMO 2: Generate 5 amazing answers\n",
        "print(\"ASSIGNMENT DEMO 2: AMAZING ANSWERS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question = \"What do patients say about the medical staff?\"\n",
        "result = assignment_chatbot(question, mode=\"amazing\")\n",
        "\n",
        "print(f\"\\nResult: {result['success']}\")\n",
        "print(f\"Mode: {result['mode']}\")\n",
        "print(f\"Count: {result['count']}\")\n",
        "print(f\"Time: {result['execution_time']}s\")\n",
        "\n",
        "if result['answers']:\n",
        "    print(f\"\\nAMAZING ANSWERS ({len(result['answers'])} total):\")\n",
        "    for i, answer in enumerate(result['answers'], 1):\n",
        "        print(f\"\\n{i}. {answer}\")\n",
        "        print(\"-\" * 40)\n",
        "else:\n",
        "    print(f\"Error: {result['message']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## Assignment Complete!\n",
        "\n",
        "### Requirements Met:\n",
        "- **1 Incorrect Answer**: `assignment_chatbot(question, mode=\"incorrect\")`\n",
        "- **5 Amazing Answers**: `assignment_chatbot(question, mode=\"amazing\")`\n",
        "- **Google Colab Ready**: No API keys, all free models\n",
        "\n",
        "### Usage:\n",
        "```python\n",
        "# Generate 1 incorrect answer\n",
        "result = assignment_chatbot(\"Your question\", mode=\"incorrect\")\n",
        "\n",
        "# Generate 5 amazing answers  \n",
        "result = assignment_chatbot(\"Your question\", mode=\"amazing\")\n",
        "\n",
        "# Random choice\n",
        "result = assignment_chatbot(\"Your question\", mode=\"random\")\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}